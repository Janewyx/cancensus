---
title: "CensusMapper import playground"
output: html_notebook
---

We demonstrate how to import data from the [CensusMapper](https://CensusMapper.ca) API. The code for this notbook can be found on [GitHub](https://github.com/mountainMath/r-censusmapper).

To work with the CensusMapper API we need to specify our API key. We load the API key in the environment variable "CM_API_KEY", which we assume was set prior to running the script. We could also specify it directly in the code, but than we have to be careful not to expose our API key when sharing our code.

```{r API Key, echo=TRUE}
# set environment variable via 
# Sys.setenv(CM_API_KEY='<your API key>')

api_key=Sys.getenv('CM_API_KEY')
```


To tie into the CensusMapper API we utilize the "census_mapper" convenience function to load census data from CensusMapper.

```{r CensusMapper Convenience Function, include=FALSE}

library(digest)
library(sf)
library(jsonlite)
library(httr)
library(dplyr)
library(readr)

census_geodata <- function (dataset, level, regions, vectors,api_key, geo=FALSE,force_download=FALSE) {
  
  base_url="https://CensusMapper.ca/api/v1/"
  # load data variables
  vectors_string=toJSON(vectors)
  data_param_string=paste(
    paste('regions',regions,sep='='),
    paste('vectors',vectors_string,sep='='),
    paste('level',level,sep='='),
    paste('dataset',dataset,sep='=')
    ,sep='&')
  data_hash=digest(data_param_string,algo='md5')
  dir.create('data_cache', showWarnings = FALSE)
  data_file=paste('data_cache/CM_data_',data_hash,'.csv',sep='')
  data_base_url=paste0(base_url,'data.csv')
  if (force_download || !file.exists(data_file)) {
    final_data_param_string=paste(data_param_string,paste('api_key',api_key,sep='='),sep='&')
    GET(paste(data_base_url,final_data_param_string,sep='?'),write_disk(data_file),progress());
  }
  dat <- read_csv(data_file, na = c("x","F")) %>%
    mutate(GeoUID = as.character(GeoUID),
           Type = as.factor(Type),
           `Region Name` = as.factor(`Region Name`))
  
  
  if (geo) {
    geo_param_string=paste(
      paste('regions',regions_string,sep='='),
      paste('level',level,sep='='),
      paste('dataset',dataset,sep='=')
      ,sep='&')
    geo_hash=digest(geo_param_string,algo='md5')
    geo_file=paste('data_cache/CM_geo_',geo_hash,'.geojson',sep='')
    if (force_download || !file.exists(geo_file)) {
      final_geo_param_string=paste(geo_param_string,paste('api_key',api_key,sep='='),sep='&')
      geo_base_url=paste0(base_url,'geo.geojson')
      GET(paste(geo_base_url,final_geo_param_string,sep='?'),write_disk(geo_file));
      #download.file(paste(geo_base_url,final_geo_param_string,sep='?'),geo_file)
    }
    geos=read_sf(geo_file)
    geos$id <- as.character(geos$id)
    result <- inner_join(geos, dat, by = c("id" ="GeoUID"))
    
  } else {
    result=dat
  }
  return(result)
}

# Other functions
census_geo <- function(dataset, level, regions,api_key,force_download=FALSE) {
  base_url="https://CensusMapper.ca/api/v1/"
  geo_param_string=paste(
    paste('regions',regions_string,sep='='),
    paste('level',level,sep='='),
    paste('dataset',dataset,sep='=')
    ,sep='&')
  geo_hash=digest(geo_param_string,algo='md5')
  geo_file=paste('data_cache/CM_geo_',geo_hash,'.geojson',sep='')
  if (force_download || !file.exists(geo_file)) {
    final_geo_param_string=paste(geo_param_string,paste('api_key',api_key,sep='='),sep='&')
    geo_base_url=paste0(base_url,'geo.geojson')
    GET(paste(geo_base_url,final_geo_param_string,sep='?'),write_disk(geo_file));
    #download.file(paste(geo_base_url,final_geo_param_string,sep='?'),geo_file)
  }
  geos=read_sf(geo_file)
  return(geos)
}
census_data <- function(dataset, level, regions, vectors,api_key,force_download=FALSE) {
  
  base_url="https://CensusMapper.ca/api/v1/"
  # load data variables
  vectors_string=toJSON(vectors)
  data_param_string=paste(
    paste('regions',regions,sep='='),
    paste('vectors',vectors_string,sep='='),
    paste('level',level,sep='='),
    paste('dataset',dataset,sep='=')
    ,sep='&')
  data_hash=digest(data_param_string,algo='md5')
  dir.create('data_cache', showWarnings = FALSE)
  data_file=paste('data_cache/CM_data_',data_hash,'.csv',sep='')
  data_base_url=paste0(base_url,'data.csv')
  if (force_download || !file.exists(data_file)) {
    final_data_param_string=paste(data_param_string,paste('api_key',api_key,sep='='),sep='&')
    GET(paste(data_base_url,final_data_param_string,sep='?'),write_disk(data_file),progress());
  }
  dat <- read_csv(data_file, na = c("x","F")) %>%
    mutate(GeoUID = as.character(GeoUID),
           Type = as.factor(Type),
           `Region Name` = as.factor(`Region Name`))
  return(dat)
}

```


As an example we choose the "occupied dwellings by structural type of dwelling" data from 2016, CT level, for the Vancouver CMA. The CensusMapper convenience function expects the year (2016), aggregation level (CT), geographies (CMA 59993), and CensusMapper internal variable names as input. We also need to speficy the CensusMapper API key for access. Lastly we may specify the "geo" flag, if it is set to TRUE we will also load the spatial data.

```{r, echo=TRUE, message=TRUE, warning=TRUE}
vectors=c("v_CA16_408","v_CA16_409","v_CA16_410","v_CA16_412","v_CA16_413","v_CA16_414","v_CA16_415","v_CA16_416","v_CA16_417")
regions_string='{"CMA":["59933"]}'

# Tests
geodata_test <- census_geodata(dataset='CA16',level='CT',regions=regions_string,vectors=vectors,api_key=api_key,geo=TRUE, force_download = FALSE)
data_test <- census_data(dataset='CA16',level='CT',regions=regions_string,vectors=vectors,api_key=api_key)
geo_test <- census_geo(dataset='CA16',level='CT',regions=regions_string,api_key=api_key)

# Checking which rows have NA
# which(is.na(data_test), arr.ind=TRUE)
# This does not account for the 78 observation discrepancy - only 12 rows contain NA. 

```

Compute some values for mapping

```{r, echo=TRUE}
geos$sd <- geos$v_CA16_409..Single.detached.house / geos$v_CA16_408..Occupied.private.dwellings.by.structural.type.of.dwelling.data
#geos$sd[geos$v_CA16_409..Single.detached.house=='x']<-NA
```


Now we can use that data for analysis or mapping.


```{r, echo=TRUE}
library(tmap)
tm_shape(geos) +
  tm_polygons("sd", style="quantile", title="Single Detached Homes")
```

Or using the ggplot library.

```{r, echo=TRUE}

# requires dev build of tiverse/ggplot2, install using devtools and install_github('tidyverse/ggplot2') if needed
library(sf)
library(tidyverse)
library(viridis)
library(rvest)


ggplot(geos) +
  geom_sf(aes(fill = sd)) +
  scale_fill_viridis("%SD") +
  ggtitle("Proportion of Dwelling Units that are Single Detached") +
  theme_bw()
```


Or we can explore the data through non-map based means, for example how the proportion of single detached and duplex dwelling relate. Duplex dwellings are in most cases suited single family homes. We can explore how the relationship between single family homes and duplexes depend on the municipal regulations allowing for secondary suites.

```{r}
geos$duplex <- geos$v_CA16_414..Apartment.or.flat.in.a.duplex/ geos$v_CA16_408..Occupied.private.dwellings.by.structural.type.of.dwelling.data

geos$color_code <- ifelse(geos$Region.Name == "Vancouver", 'red', ifelse(geos$Region.Name == "Burnaby", 'blue', ifelse(geos$Region.Name == "Surrey", 'green', 'grey')))

plot(geos$sd, geos$duplex, xlab="Single Detached", ylab="Duplex", col=geos$color_code)
```


